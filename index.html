
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Aoran XIAO's Homepage</title>
  
  <meta name="author" content="Aoran Xiao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/VIL.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Aoran.jpg", target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Aoran.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:left; display: flex; align-items: center;" >
                <name>Aoran XIAO (肖傲然)</name>
              </p>
              <p style="line-height: 1.8em;">​Research Fellow
                <br>
                College of Computing and Data Science
                <br>
                Nanyang Technological University, Singapore
                <br>
                Email: aoran.xiao [at] ntu.edu.sg
              </p>
              <p style="text-align:left;">
                <span class="icon" style="margin: 0.8%;"><a href="https://scholar.google.com/citations?user=yGKsEpAAAAAJ&hl", target="_blank"><img src="images/icons/scholar.png" alt="google scholar"></a></span>
                <span class="icon" style="margin: 0.8%;"><a href="https://github.com/xiaoaoran", target="_blank"><img src="images/icons/github.png" alt="gitjub"></a></span>

              </p>
            </td>

          </tr>
        </tbody></table>

        <heading>Short Bio</heading>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-left:20px;width:100%;vertical-align:middle">
              <p>
                ​I am currently a Research Fellow at <a href="https://www.ntu.edu.sg/computing">College of Computing and Data Science(CCDS)</a>, Nanyang Technological University (NTU), Singapore, where I work on deep learning, point cloud understanding, and computer vision, etc., supervised by Prof. <a href="https://personal.ntu.edu.sg/shijian.lu/">Shijian Lu</a>. Before that, I got my PhD in computer science and engineering from NTU. I obtained my Master degree at <a href="http://www.lmars.whu.edu.cn/en/">LIESMARS</a> of <a href="https://en.whu.edu.cn">Wuhan University</a>, China, where I was co-advised by Prof. <a href="http://www.lmars.whu.edu.cn/prof_web/prof_lideren/index.htm">Deren Li</a></a> and Prof. <a href="http://castf.org/pages/chenruizhi/chenruizhi-intro.html">Ruizhi Chen</a></a>. I did my bachelors at <a href="https://rsgis.whu.edu.cn">School of Remote Sensing and Information Engineering</a>, <a href="https://en.whu.edu.cn">Wuhan University</a>.
              </p>
              <p>
                My research interest lies in point cloud recognition, computer vision and remote sensing.
              </p>
            </td>
          </tr>
        </tbody></table>

        <heading>News</heading>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-left:20px;width:100%;vertical-align:middle">
              <p>
                [2024-07] Our CAT-SAM is accepted to ECCV2024! <br>
                [2024-06] Our survey for label-efficient learning of 3D point clouds is accepted to TPAMI!
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <heading>Selected Publications</heading>
        <table class="paper-container"><tbody>
          <br>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/CAT-SAM.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>CAT-SAM: Conditional Tuning for Few-Shot Adaptation of Segment Anything Model</papertitle>
              <br>
              <strong>Aoran Xiao*</strong>, Weihao Xuan*, Heli Qi, Yun Xing, Ruijie Ren, Xiaoqin Zhang, Ling Shao, Shijian Lu (*Equal contribution)
              <br>
              <em>European Conference on Computer Vision (<b>ECCV</b>), 2024. (<b>Oral paper</b>)</em>
              <br>
              [<a href="https://arxiv.org/pdf/2402.03631.pdf",  target="_blank">paper</a>] [<a href="https://xiaoaoran.github.io/projects/CAT-SAM",  target="_blank">project</a>]
            </p>
            </td>
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/label_efficient.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>A Survey of Label-Efficient Deep Learning for 3D Point Clouds</papertitle>
              <br>
              <strong>Aoran Xiao</strong>, Xiaoqin Zhang, Ling Shao, Shijian Lu.
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>), 2024.</em>
              <br>
              [<a href="https://arxiv.org/pdf/2305.19812.pdf",  target="_blank">paper</a>] [<a href="https://github.com/xiaoaoran/3D_label_efficient_learning",  target="_blank">project</a>]
            </p>
            </td>
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/SCT.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Domain Adaptive LiDAR Point Cloud Segmentation With 3D Spatial Consistency</papertitle>
              <br>
              <strong>Aoran Xiao</strong>, Dayan Guan, Xiaoqin Zhang, Shijian Lu
              <br>
              <em>IEEE Transactions on Multimedia (<b>T-MM</b>), 2024.</em>
              <br>
              [<a href="pub/Domain_Adaptive_LiDAR_Point_Cloud_Segmentation_With_3D_Spatial_Consistency.pdf",  target="_blank">paper</a>]
            </p>
            </td>
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/CoCu.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Rewrite Caption Semantics: Bridging Semantic Gaps for Language-Supervised Semantic Segmentation</papertitle>
              <br>
              Yun Xing, Jian Kang, <strong>Aoran Xiao</strong>, Jiahao Nie, Ling Shao, Shijian Lu
              <br>
              <em>Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2023.</em>
              <br>
              [<a href="https://arxiv.org/pdf/2309.13505.pdf",  target="_blank">paper</a>] [<a href="https://github.com/xing0047/CoCu",  target="_blank">project</a>]
            </p>
            </td>
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/SemanticSTF.gif" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds</papertitle>
              <br>
              <strong>Aoran Xiao</strong>, Jiaxing Huang, Weihao Xuan, Ruijie Ren, Kangcheng Liu, Dayan Guan, Abdulmotaleb El Saddik, Shijian Lu, Eric Xing.
              <br>
              <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (<b>CVPR</b>), 2023.</em>
              <br>
              [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_3D_Semantic_Segmentation_in_the_Wild_Learning_Generalized_Models_for_CVPR_2023_paper.pdf",  target="_blank">paper</a>] [<a href="https://github.com/xiaoaoran/SemanticSTF",  target="_blank">project</a>]
            </p>
            </td>
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/point_ssl_survey.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Unsupervised Representation Learning for Point Clouds with Deep Neural Networks: A Survey</papertitle>
              <br>
              <strong>Aoran Xiao*</strong>, Jiaxing Huang*, Dayan Guan, Xiaoqin Zhang, Shijian Lu (*Equal contribution).
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>), 2023.</em>
              <br>
              [<a href="https://arxiv.org/pdf/2202.13589.pdf",  target="_blank">paper</a>] [<a href="https://github.com/xiaoaoran/3d_url_survey",  target="_blank">project</a>]
            </p>
            </td>
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/polarmix.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>PolarMix: A General Data Augmentation Technique for LiDAR Point Clouds</papertitle>
              <br>
              <strong>Aoran Xiao</strong>, Jiaxing Huang, Dayan Guan, Kaiwen Cui, Shijian Lu, Ling Shao.
              <br>
              <em>Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2022.</em>
              <br>
              [<a href="https://arxiv.org/abs/2208.00223",  target="_blank">paper</a>] [<a href="https://github.com/xiaoaoran/polarmix",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/caco.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Category Contrast for Unsupervised Domain Adaptation in Visual Tasks</papertitle>
              <br>
              Jiaxing Huang, Dayan Guan, <strong>Aoran Xiao</strong>, Shijian Lu, Ling Shao.
              <br>
              <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (<b>CVPR</b>), 2022.</em>
              <br>
              [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Category_Contrast_for_Unsupervised_Domain_Adaptation_in_Visual_Tasks_CVPR_2022_paper.pdf",  target="_blank">paper</a>] [<a href="https://github.com/jxhuang0508/CaCo",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/Unbiased.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Unbiased Subclass Regularization for Semi-Supervised Semantic Segmentation</papertitle>
              <br>
              Dayan Guan, Jiaxing Huang, <strong>Aoran Xiao</strong>, Shijian Lu, Ling Shao.
              <br>
              <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (<b>CVPR</b>), 2022.</em>
              <br>
              [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Unbiased_Subclass_Regularization_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf",  target="_blank">paper</a>] [<a href="https://github.com/Dayan-Guan/USRN",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/point_transfer.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Transfer Learning from Synthetic to Real LiDAR Point Cloud for Semantic Segmentation</papertitle>
              <br>
              <strong>Aoran Xiao</strong>, Jiaxing Huang, Dayan Guan, Fangneng Zhan, Shijian Lu.
              <br>
              <em>AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2022.</em>
              <br>
              [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/20183/19942",  target="_blank">paper</a>] [<a href="https://github.com/xiaoaoran/SynLiDAR",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/hcl.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data</papertitle>
              <br>
              Jiaxing Huang, Dayan Guan, <strong>Aoran Xiao</strong>, Shijian Lu
              <br>
              <em>Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2021.</em>
              <br>
              [<a href="https://proceedings.neurips.cc/paper/2021/file/1dba5eed8838571e1c80af145184e515-Paper.pdf",  target="_blank">paper</a>] [<a href="https://github.com/jxhuang0508/HCL",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/rda.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>RDA: Robust Domain Adaptation via Fourier Adversarial Attacking</papertitle>
              <br>
              Jiaxing Huang, Dayan Guan, <strong>Aoran Xiao</strong>, Shijian Lu
              <br>
              <em>International Conference on Computer Vision (<b>ICCV</b>), 2021.</em>
              <br>
              [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_RDA_Robust_Domain_Adaptation_via_Fourier_Adversarial_Attacking_ICCV_2021_paper.pdf",  target="_blank">paper</a>] [<a href="https://github.com/jxhuang0508/RDA",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/davideo.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Domain Adaptive Video Segmentation via Temporal Consistency Regularization</papertitle>
              <br>
              Dayan Guan, Jiaxing Huang, <strong>Aoran Xiao</strong>, Shijian Lu
              <br>
              <em>International Conference on Computer Vision (<b>ICCV</b>), 2021.</em>
              <br>
              [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Guan_Domain_Adaptive_Video_Segmentation_via_Temporal_Consistency_Regularization_ICCV_2021_paper.pdf",  target="_blank">paper</a>] [<a href="https://github.com/Dayan-Guan/DA-VSN",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/cvrn.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Cross-View Regularization for Domain Adaptive Panoptic Segmentation</papertitle>
              <br>
              Jiaxing Huang, Dayan Guan, <strong>Aoran Xiao</strong>, Shijian Lu, Ling Shao.
              <br>
              <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (<b>CVPR</b>), 2021.</em>
              <br>
              [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Cross-View_Regularization_for_Domain_Adaptive_Panoptic_Segmentation_CVPR_2021_paper.pdf",  target="_blank">paper</a>] [<a href="https://github.com/jxhuang0508/CVRN",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/fsdr.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>FSDR: Frequency Space Domain Randomization for Domain Generalization</papertitle>
              <br>
              Jiaxing Huang, Dayan Guan, <strong>Aoran Xiao</strong>, Shijian Lu, Ling Shao.
              <br>
              <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (<b>CVPR</b>), 2021.</em>
              <br>
              [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_FSDR_Frequency_Space_Domain_Randomization_for_Domain_Generalization_CVPR_2021_paper.pdf",  target="_blank">paper</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/fpsnet.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>FPS-Net: A convolutional fusion network for large-scale LiDAR point cloud segmentation</papertitle>
              <br>
              <strong>Aoran Xiao</strong>, Xiaofei Yang, Shijian Lu, Dayan Guan, Jiaxing Huang.
              <br>
              <em>ISPRS journal of Photogrammetry and Remote Sensing, 2021.</em>
              <br>
              [<a href="https://arxiv.org/pdf/2103.00738",  target="_blank">paper</a>] [<a href="https://github.com/xiaoaoran/FPS-Net",  target="_blank">project</a>]
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="images/papers/undet.png" alt="clean-usnob" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>Uncertainty-Aware Unsupervised Domain Adaptation in Object Detection</papertitle>
              <br>
              Dayan Guan, Jiaxing Huang, <strong>Aoran Xiao</strong>, Shijian Lu, Yanpeng Cao.
              <br>
              <em>IEEE Transactions on Multimedia (<b>T-MM</b>), 2021.</em>
              <br>
              [<a href="https://arxiv.org/abs/2103.00236",  target="_blank">paper</a>] [<a href="https://github.com/Dayan-Guan/UaDAN",  target="_blank">project</a>]
          </tr>
        </tbody></table>

        <heading>Released Datasets</heading>
        <table class="paper-container"><tbody>
          <br>
          <tr>
            <td class="paper-item-img">
              <img src="images/papers/synlidar.gif" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>SynLiDAR: A Large-Scale Synthetic LiDAR Point Cloud Dataset with Point-Wise Annotations</papertitle>
              <br>
              SynLiDAR is a large-scale synthetic LiDAR sequential point cloud dataset with point-wise annotations. 13 sequences of LiDAR point cloud with around 20k scans (over 19 billion points and 32 semantic classes) are collected from virtual urban cities, suburban towns, neighborhood, and harbor.
              <br>
              [<a href="https://arxiv.org/abs/2107.05399",  target="_blank">paper</a>] [<a href="https://github.com/xiaoaoran/SynLiDAR",  target="_blank">project</a>] [<a href="https://docs.google.com/forms/d/e/1FAIpQLScZR3re0YFn59mlnag8s7vD5p4JaMkX2oxug5rn1K5bc5C-4g/viewform?pli=1",  target="_blank">download</a>]
            </p>
            </td>
          </tr>

          <tr>
            <td class="paper-item-img">
              <img src="./images/papers/SemanticSTF.gif" width="200" height="100">
            </td>
            <td width="75%" valign="middle">
              <p style="line-height: 1.8em;">
              <papertitle>SemanticSTF: An Adverse-Weather LiDAR Point Cloud Dataset</papertitle>
              <br>
              SemanticSTF is a large-scale adverse-weather point cloud dataset that provides dense point-level annotations and allows to study 3D semantic segmentation under various adverse weather conditions.
              <br>
              [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_3D_Semantic_Segmentation_in_the_Wild_Learning_Generalized_Models_for_CVPR_2023_paper.pdf",  target="_blank">paper</a>] [<a href="https://github.com/xiaoaoran/SemanticSTF",  target="_blank">project</a>] [<a href="https://docs.google.com/forms/d/e/1FAIpQLSeChw4k27lUUspcLeD4af1C_HtPxhsCCCZTcU8QxpTsDvdDng/viewform",  target="_blank">download</a>]
            </p>
            </td>
          </tr>
        </tbody></table>
    
        <heading>Miscellaneous</heading> 
        <br><br>
        <table class="news" width="100%" align="center" border="0" cellpadding="0"><tbody>
          <tr>
            <td width="100%" valign="center">
              <subheading>Professional Activities</subheading>
              <ul style="height: auto;">
                <li>Conference Reviews:</li>
              </ul>
              <p style="padding-left: 6%; line-height: 1.5em;">International Conference on Computer Vision (ICCV) 2023.<br>
              IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024,2023,2022.<br>
              Conference and Workshop on Neural Information Processing Systems (NeurIPS) 2024,2023.<br>
              European Conference on Computer Vision (ECCV) 2024, 2022.<br>
              International Conference on Learning Representations (ICLR) 2024.<br>
              International Conference on Machine Learning (ICML) 2024.<br>
              AAAI Conference on Artificial Intelligence (AAAI) 2025,2024.<br>
              International Conference on Robotics and Automation (ICRA) 2024.<br>
              <ul style="height: auto;">
                <li>Journal Reviews:</li>
              </ul>
              <p style="padding-left: 6%; line-height: 1.5em;">IEEE Transactions on Image Processing (TIP).<br>
              IEEE Transactions on Intelligent Vehicles (TIV).<br>
              IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).<br>
              ISPRS Journal of Photogrammetry and Remote Sensing.<br>
              Pattern Recognition.<br>
            </td>
          </tr>
        </tbody></table>
        
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=BeXrlI9ts-nayEItO_gDSrwVCCEIuU-hnwtZy-zYVbg'></script>

        <footer>
          <p style="text-align:center"> © XIAO Aoran | Last updated: Jul 2023</p>
          <p style="text-align:center;font-size:small;">
            Design and source code from <a style="font-size:small;" href="https://jonbarron.info", target="_blank">Jon Barron's website</a>.
          </a></p>
        </footer>


      </td>
    </tr>
  </table>
</body>

</html>