<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-size:32px;
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>CAT-SAM</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:30px"><b>[ECCV2024 (Oral)] CAT-SAM: Conditional Tuning <br>for Few-Shot Adaptation of Segment Anything Model</b></span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://xiaoaoran.github.io">Aoran Xiao<sup>*1</sup></a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://weihaoxuan.com">Weihao Xuan<sup>*2,3</sup></a></a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://scholar.google.co.jp/citations?user=CH-rTXsAAAAJ&hl=en">Heli Qi<sup>4</sup></a></a></span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://scholar.google.co.jp/citations?user=uOAYTXoAAAAJ&hl=en">Yun Xing<sup>1</sup></a></span>
						</center>
					</td>
			</table>
			<table align=center width=600px>
                    <td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://ruijieren.com">Ruijie Ren<sup>5</sup></a></span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://ieeexplore.ieee.org/author/37405025600">Xiaoqin Zhang<sup>6</sup></a></span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://scholar.google.com/citations?user=z84rLjoAAAAJ&hl=en">Ling Shao<sup>7</sup></a></span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:20px"><a href="https://scholar.google.com/citations?user=uYmK-A0AAAAJ&hl=en">Shijian Lu<sup>1</sup></a></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=350px>
				<td align=center width=200px>
					<span style="font-size:20px">Nanyang Technological University<sup>1</sup></span>
				</td>
			</table>
			<table align=center width=350px>
				<td align=center width=200px>
					<span style="font-size:20px">The University of Tokyo<sup>2</sup></span>
				</td>
			</table>
			<table align=center width=350px>
				<td align=center width=200px>
					<span style="font-size:20px">RIKEN AIP<sup>3</sup></span>
				</td>
			</table>
			<table align=center width=450px>
				<td align=center width=300px>
					<span style="font-size:20px">Nara Institute of Science and Technology<sup>4</sup></span>
				</td>
			</table>
			<table align=center width=450px>
				<td align=center width=300px>
					<span style="font-size:20px">Waseda University<sup>5</sup></span>
				</td>
			</table>
			<table align=center width=450px>
				<td align=center width=300px>
					<span style="font-size:20px">Wenzhou University<sup>6</sup></span>
				</td>
			</table>
			<table align=center width=450px>
				<td align=center width=300px>
					<span style="font-size:20px">UCAS-Terminus AI Lab, UCAS<sup>7</sup></span>
				</td>
			</table>
			<table>
				<td align=center width=300px>
					<span style="font-size:16px"><sup>*</sup>Equally contributing first authors</span>
				</td>
			</table>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:20px"><a href='https://arxiv.org/abs/2402.03631'>[arXiv]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:20px"><a href='https://github.com/weihao1115/cat-sam'>[code]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<table align=center width=850px>
		<center><h1><span style="text-align: center;">Video</span></h1></center>
		<tr>
			<iframe width="100%" height="100%" class="elementor-video-iframe" src="https://www.youtube.com/embed/745tBSLk8PY?si=UbaSNRkC9xB0QCzr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
			</iframe>
		</tr>
	</table>

	<hr>

	<table align=center width=850px>
		<center><h1><span style="font-size:24px">Abstract</span></h1></center>
		<tr>
			<td>
				The Segment Anything Model (SAM) has demonstrated remarkable zero-shot capability and flexible geometric prompting in general image segmentation. However, it often struggles in domains that are either sparsely represented or lie outside its training distribution, such as aerial, medical, and non-RGB images. Recent efforts have predominantly focused on adapting SAM to these domains using fully supervised methods, which necessitate large amounts of annotated training data and pose practical challenges in data collection. This paper presents CAT-SAM, a ConditionAl Tuning network that explores <i>few-shot</i> adaptation of SAM toward various challenging downstream domains in a data-efficient manner. The core design is a <i>prompt bridge</i> structure that enables <i>decoder-conditioned joint tuning</i> of the heavyweight image encoder and the lightweight mask decoder. The bridging maps the domain-specific features of the mask decoder to the image encoder, fostering synergic adaptation of both components with mutual benefits with few-shot target samples only, ultimately leading to superior segmentation in various downstream tasks. We develop two CAT-SAM variants that adopt two tuning strategies for the image encoder: one injecting learnable prompt tokens in the input space and the other inserting lightweight adapter networks. Extensive experiments over 11 downstream tasks show that CAT-SAM achieves superior segmentation consistently even under the very challenging one-shot adaptation setup.
			</td>
		</tr>
	</table>
	<br>

	<hr>

	<center>
		<table align=center width=1000px>
		<center><h1><span style="font-size:24px">Method</span></h1></center>
			<tr>
				<td width=1000px>
					<center>
<!--						<img class="round" style="width:1000px" src="https://github.com/xiaoaoran/xiaoaoran.github.io/blob/master/images/papers/CAT-SAM.png"/>-->
						<img class="round" style="width:1000px" src="../images/papers/CAT-SAM.png"/>
					</center>
				</td>
			</tr>
		</table>

	<hr>

		<div style="text-align: center;">
		<center><h1><span style="font-size:24px">Experiments</span></h1></center>
			<table border="1" style="margin: auto">
				<center>
				<thead>
					<tr>
						<th>Model</th>
						<th>#Tuning Sample</th>
						<th>WHU (IoU&uarr;)</th>
						<th>Kvasir (mIoU&uarr;)</th>
						<th>SBU-Shadow (BER&darr;)</th>
						<th>JSRT (mIoU&uarr;)</th>
						<th>FLS (mIoU&uarr;)</th>
						<th>HRSID (AP&uarr;)</th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>SAM</td>
						<td>-</td>
						<td>43.5</td>
						<td>79.0</td>
						<td>62.4</td>
						<td>78.5</td>
						<td>69.7</td>
						<td>38.2</td>
					</tr>
					<tr>
						<td>CAT-SAM-T</td>
						<td rowspan="2">1-shot</td>
						<td>86.8</td>
						<td>83.4</td>
						<td>78.0</td>
						<td>93.0</td>
						<td>N/A</td>
						<td>46.2</td>
					</tr>
					<tr>
						<td>CAT-SAM-A</td>
						<td>88.2</td>
						<td>85.4</td>
						<td>81.9</td>
						<td>92.6</td>
						<td>N/A</td>
						<td>44.9</td>
					</tr>
					<tr>
						<td>CAT-SAM-T</td>
						<td rowspan="2">16-shots</td>
						<td>89.6</td>
						<td>93.1</td>
						<td>4.04</td>
						<td>94.2</td>
						<td>73.2</td>
						<td>46.2</td>
					</tr>
					<tr>
						<td>CAT-SAM-A</td>
						<td>90.3</td>
						<td>93.6</td>
						<td>3.80</td>
						<td>93.5</td>
						<td>71.4</td>
						<td>45.7</td>
					</tr>
					<tr>
						<td>CAT-SAM-T</td>
						<td rowspan="2">Full-shots</td>
						<td>93.3</td>
						<td>94.5</td>
						<td>2.54</td>
						<td>94.4</td>
						<td>81.7</td>
						<td>51.4</td>
					</tr>
					<tr>
						<td>CAT-SAM-A</td>
						<td>93.6</td>
						<td>94.3</td>
						<td>2.39</td>
						<td>94.6</td>
						<td>82.0</td>
						<td>52.9</td>
					</tr>
				</tbody>
			</table>
		</div>

	<hr>

		<center><h1><span style="font-size:24px">Visual Results</span></h1></center>
		<figure>
  			<p><img src="../images/papers/CAT-SAM-QualitativeResults.png" width="1000" alt="Eiffel tower">
  			<figcaption>
    			Visual comparisons of SAM (top row) and CAT-SAM (bottom row). We illustrate samples from WHU for building segmentation, MA. Roads for road segmentation, SBU-Shadow for shadow segmentation, Kvasir for polyp segmen- tation, JSRT for chest organ segmentation (X-ray images), FLS for marine debris segmentation (Sonar images), and HRSID for ship instance segmentation (SAR images). CAT-SAM exhibits one-shot adaptation across most datasets, except for 16-shot over FLS. Red boxes and stars denote geometric prompts, colored regions are mask predictions, and lines show the boundary of ground truth segmentation.
		    </figcaption>
		</figure>
	<hr>
<!--	<center><h1>Talk</h1></center>-->
<!--	<p align="center">-->
<!--		<iframe width="660" height="395" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>-->
<!--	</p>-->

<!--	<table align=center width=800px>-->
<!--		<br>-->
<!--		<tr>-->
<!--			<center>-->
<!--				<span style="font-size:28px"><a href=''>[Slides]</a>-->
<!--				</span>-->
<!--			</center>-->
<!--		</tr>-->
<!--	</table>-->
<!--	<hr>-->

	<table align=center width=850px>
		<center><h1><span style="font-size:24px">Citation</span></span></h1></center>
		<tr>
			<td>
				<pre>
		@article{xiao2024cat,
		  title={CAT-SAM: Conditional Tuning Network for Few-Shot Adaptation of Segmentation Anything Model},
		  author={Xiao, Aoran and Xuan, Weihao and Qi, Heli and Xing, Yun and Ren, Ruijie and Zhang, Xiaoqin and Ling, Shao and Lu, Shijian},
		  journal={arXiv preprint arXiv:2402.03631},
		  year={2024}
		}
				</pre>
			</td>
		</tr>
	</table>
	<br>

<br>
</body>
</html>
